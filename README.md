# emotion_rec
Emotion Recognition 

The  proposed model will be a multi-class LSTM model for emotion recognition of speech signals. 



Toronto Emotional Speech Set Data (TESS)
Ryerson Audio-Visual Database of Emotional Speech and Song(RAVDESS)
Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D)
Interactive Emotional Dyadic Motion Capture (IEMOCAP)


The Target column (y) will be the emotion classification.



Feature extraction will be done to extract Mel-frequency cepstral coefficients as numerical features
