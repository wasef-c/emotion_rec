{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wasef-c/emotion_rec/blob/main/BiLSTM_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKcrv_T-758b"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm, tqdm_notebook; tqdm.pandas() # Progress bar\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "# from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "from tensorflow.keras.layers import (Dense, Bidirectional, ELU,\n",
        "                          Dropout, LeakyReLU, Conv1D, BatchNormalization)\n",
        "from keras.models import Sequential\n",
        "# from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Set seed for reproducability\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "t_start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMOTIONS  = {\n",
        "    0: 'neutral',\n",
        "    1: 'happy',\n",
        "    2: 'sad',\n",
        "    3: 'angry',\n",
        "    4: 'fearful',\n",
        "    5: 'disgust',\n",
        "}"
      ],
      "metadata": {
        "id": "sfzbfeGXudHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm9iEJynIFHe",
        "outputId": "203a763a-4f04-428c-e712-7d65f75b5b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = r'/content/drive/MyDrive/MaSc/emo_rec/Saved_Sets/008'\n",
        "X = np.load(os.path.join(save_directory, 'X_Tr008.npy'))\n",
        "Y = np.load(os.path.join(save_directory, 'Y_Tr008.npy'))\n",
        "\n",
        "\n",
        "X_test = np.load(os.path.join(save_directory, 'X_Te008.npy'))\n",
        "Y_test = np.load(os.path.join(save_directory, 'Y_Te008.npy'))"
      ],
      "metadata": {
        "id": "R5Ny65zFuu05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "x_train_padded = pad_sequences(x_train, maxlen=87, padding='post', truncating='post')\n",
        "x_val_padded = pad_sequences(x_val, maxlen=87, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "cTT8e_DrBoUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def splitIntoChunks(mel_spec,win_size,stride):\n",
        "    t = mel_spec.shape[1]\n",
        "    num_of_chunks = int(t/stride)\n",
        "    chunks = []\n",
        "    for i in range(num_of_chunks):\n",
        "        chunk = mel_spec[:,i*stride:i*stride+win_size]\n",
        "        if chunk.shape[1] == win_size:\n",
        "            chunks.append(chunk)\n",
        "    return np.stack(chunks,axis=0)\n",
        "\n",
        "\n",
        "class TimeDistributed(nn.Module):\n",
        "    def __init__(self, module):\n",
        "        super(TimeDistributed, self).__init__()\n",
        "        self.module = module\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if len(x.size()) <= 2:\n",
        "            return self.module(x)\n",
        "        # squash samples and timesteps into a single axis\n",
        "        elif len(x.size()) == 3: # (samples, timesteps, inp1)\n",
        "            x_reshape = x.contiguous().view(-1, x.size(2))  # (samples * timesteps, inp1)\n",
        "        elif len(x.size()) == 4: # (samples,timesteps,inp1,inp2)\n",
        "            x_reshape = x.contiguous().view(-1, x.size(2), x.size(3)) # (samples*timesteps,inp1,inp2)\n",
        "        else: # (samples,timesteps,inp1,inp2,inp3)\n",
        "            x_reshape = x.contiguous().view(-1, x.size(2), x.size(3),x.size(4)) # (samples*timesteps,inp1,inp2,inp3)\n",
        "\n",
        "        y = self.module(x_reshape)\n",
        "\n",
        "        # we have to reshape Y\n",
        "        if len(x.size()) == 3:\n",
        "            y = y.contiguous().view(x.size(0), -1, y.size(1))  # (samples, timesteps, out1)\n",
        "        elif len(x.size()) == 4:\n",
        "            y = y.contiguous().view(x.size(0), -1, y.size(1), y.size(2)) # (samples, timesteps, out1,out2)\n",
        "        else:\n",
        "            y = y.contiguous().view(x.size(0), -1, y.size(1), y.size(2),y.size(3)) # (samples, timesteps, out1,out2, out3)\n",
        "        return y"
      ],
      "metadata": {
        "id": "4JZ6xt8MBt88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' https://github.com/Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch/blob/master/notebooks/stacked_cnn_attention_lstm.ipynb'''\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self,num_emotions, dropout_rate, hidden_size, lstm_layers):\n",
        "        super().__init__()\n",
        "        # conv block\n",
        "        self.conv2Dblock = nn.Sequential(\n",
        "            # 1. conv block\n",
        "            TimeDistributed(nn.Conv2d(in_channels=1,\n",
        "                                   out_channels=16,\n",
        "                                   kernel_size=3,\n",
        "                                   stride=1,\n",
        "                                   padding=1\n",
        "                                  )),\n",
        "            TimeDistributed(nn.BatchNorm2d(16)),\n",
        "            TimeDistributed(nn.ReLU()),\n",
        "            TimeDistributed(nn.MaxPool2d(kernel_size=2, stride=2)),\n",
        "            TimeDistributed(nn.Dropout(p=dropout_rate)),\n",
        "            # 2. conv block\n",
        "            TimeDistributed(nn.Conv2d(in_channels=16,\n",
        "                                   out_channels=32,\n",
        "                                   kernel_size=3,\n",
        "                                   stride=1,\n",
        "                                   padding=1\n",
        "                                  )),\n",
        "            TimeDistributed(nn.BatchNorm2d(32)),\n",
        "            TimeDistributed(nn.ReLU()),\n",
        "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
        "            TimeDistributed(nn.Dropout(p=dropout_rate)),\n",
        "            # 3. conv block\n",
        "            TimeDistributed(nn.Conv2d(in_channels=32,\n",
        "                                   out_channels=64,\n",
        "                                   kernel_size=3,\n",
        "                                   stride=1,\n",
        "                                   padding=1\n",
        "                                  )),\n",
        "            TimeDistributed(nn.BatchNorm2d(64)),\n",
        "            TimeDistributed(nn.ReLU()),\n",
        "            TimeDistributed(nn.MaxPool2d(kernel_size=4, stride=4)),\n",
        "            TimeDistributed(nn.Dropout(p=dropout_rate))\n",
        "        )\n",
        "        # LSTM block\n",
        "\n",
        "        # hidden_size = 64\n",
        "        self.lstm = nn.LSTM(input_size=1024,hidden_size=hidden_size,bidirectional=True, batch_first=True, num_layers=lstm_layers)\n",
        "\n",
        "        self.dropout_lstm = nn.Dropout(p=0.4)\n",
        "        self.attention_linear = nn.Linear(2*hidden_size,1) # 2*hidden_size for the 2 outputs of bidir LSTM\n",
        "        # Linear softmax layer\n",
        "        self.out_linear = nn.Linear(2*hidden_size,num_emotions)\n",
        "\n",
        "        # hidden_size = 32\n",
        "        # self.lstm = nn.LSTM(input_size=1024,hidden_size=hidden_size,bidirectional=False, batch_first=True)\n",
        "        # ''' # ADDED FOR GPU\n",
        "        # self.lstm.flatten_parameters() '''\n",
        "\n",
        "        # self.dropout_lstm = nn.Dropout(p=0.4)\n",
        "        # self.attention_linear = nn.Linear(hidden_size,1) # 2*hidden_size for the 2 outputs of bidir LSTM\n",
        "        # # Linear softmax layer\n",
        "        # self.out_linear = nn.Linear(hidden_size,num_emotions)\n",
        "    def forward(self,x):\n",
        "        conv_embedding = self.conv2Dblock(x)\n",
        "        conv_embedding = torch.flatten(conv_embedding, start_dim=2) # do not flatten batch dimension and time\n",
        "        lstm_embedding, (h,c) = self.lstm(conv_embedding)\n",
        "        lstm_embedding = self.dropout_lstm(lstm_embedding)\n",
        "        # lstm_embedding (batch, time, hidden_size*2)\n",
        "        batch_size,T,_ = lstm_embedding.shape\n",
        "        attention_weights = [None]*T\n",
        "        for t in range(T):\n",
        "            embedding = lstm_embedding[:,t,:]\n",
        "            attention_weights[t] = self.attention_linear(embedding)\n",
        "        attention_weights_norm = nn.functional.softmax(torch.stack(attention_weights,-1),dim=-1)\n",
        "        attention = torch.bmm(attention_weights_norm,lstm_embedding) # (Bx1xT)*(B,T,hidden_size*2)=(B,1,2*hidden_size)\n",
        "        attention = torch.squeeze(attention, 1)\n",
        "        output_logits = self.out_linear(attention)\n",
        "        output_softmax = nn.functional.softmax(output_logits,dim=1)\n",
        "        return output_logits, output_softmax, attention_weights_norm\n"
      ],
      "metadata": {
        "id": "FfZKR6x9BzPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fnc(predictions, targets):\n",
        "    return nn.CrossEntropyLoss()(input=predictions,target=targets)\n",
        "\n",
        "\n",
        "def make_train_step(model, loss_fnc, optimizer):\n",
        "    def train_step(X,Y):\n",
        "        # set model to train mode\n",
        "        model.train()\n",
        "        # forward pass\n",
        "        output_logits, output_softmax, attention_weights_norm = model(X)\n",
        "        predictions = torch.argmax(output_softmax,dim=1)\n",
        "        accuracy = torch.sum(Y==predictions)/float(len(Y))\n",
        "        # compute loss\n",
        "        loss = loss_fnc(output_logits, Y)\n",
        "        # compute gradients\n",
        "        loss.backward()\n",
        "        # update parameters and zero gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        return loss.item(), accuracy*100\n",
        "    return train_step\n",
        "\n",
        "def make_validate_fnc(model,loss_fnc):\n",
        "    def validate(X,Y):\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            output_logits, output_softmax, attention_weights_norm = model(X)\n",
        "            predictions = torch.argmax(output_softmax,dim=1)\n",
        "            accuracy = torch.sum(Y==predictions)/float(len(Y))\n",
        "            loss = loss_fnc(output_logits,Y)\n",
        "        return loss.item(), accuracy*100, predictions\n",
        "    return validate\n"
      ],
      "metadata": {
        "id": "Yw_BY7o3B1K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get chunks\n",
        "# train set\n",
        "mel_train_chunked = []\n",
        "for mel_spec in x_train:\n",
        "    chunks = splitIntoChunks(mel_spec, win_size=128,stride=64)\n",
        "    mel_train_chunked.append(chunks)\n",
        "print(\"Number of chunks is {}\".format(chunks.shape[0]))\n",
        "# val set\n",
        "mel_val_chunked = []\n",
        "for mel_spec in x_val:\n",
        "    chunks = splitIntoChunks(mel_spec, win_size=128,stride=64)\n",
        "    mel_val_chunked.append(chunks)\n",
        "print(\"Number of chunks is {}\".format(chunks.shape[0]))\n",
        "# test set\n",
        "mel_test_chunked = []\n",
        "for mel_spec in X_test:\n",
        "    chunks = splitIntoChunks(mel_spec, win_size=128,stride=64)\n",
        "    mel_test_chunked.append(chunks)\n",
        "print(\"Number of chunks is {}\".format(chunks.shape[0]))\n",
        "\n",
        "X_train = np.stack(mel_train_chunked,axis=0)\n",
        "X_train = np.expand_dims(X_train,2)\n",
        "print('Shape of X_train: ',X_train.shape)\n",
        "X_val = np.stack(mel_val_chunked,axis=0)\n",
        "X_val = np.expand_dims(X_val,2)\n",
        "print('Shape of X_val: ',X_val.shape)\n",
        "X_test = np.stack(mel_test_chunked,axis=0)\n",
        "X_test = np.expand_dims(X_test,2)\n",
        "print('Shape of X_test: ',X_test.shape)"
      ],
      "metadata": {
        "id": "-BtBilEhB4wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce66204-f34d-4fe8-9135-e6c063b64590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks is 1\n",
            "Number of chunks is 1\n",
            "Number of chunks is 1\n",
            "Shape of X_train:  (13010, 1, 1, 87, 128)\n",
            "Shape of X_val:  (1446, 1, 1, 87, 128)\n",
            "Shape of X_test:  (3614, 1, 1, 87, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "b,t,c,h,w = X_train.shape\n",
        "X_train = np.reshape(X_train, newshape=(b,-1))\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train = np.reshape(X_train, newshape=(b,t,c,h,w))\n",
        "\n",
        "b,t,c,h,w = X_test.shape\n",
        "X_test = np.reshape(X_test, newshape=(b,-1))\n",
        "X_test = scaler.transform(X_test)\n",
        "X_test = np.reshape(X_test, newshape=(b,t,c,h,w))\n",
        "\n",
        "b,t,c,h,w = X_val.shape\n",
        "X_val = np.reshape(X_val, newshape=(b,-1))\n",
        "X_val = scaler.transform(X_val)\n",
        "X_val = np.reshape(X_val, newshape=(b,t,c,h,w))"
      ],
      "metadata": {
        "id": "Y8YnQ-TpB7K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_train, y_train, X_val, y_val are your training and validation data\n",
        "\n",
        "\n",
        "EPOCHS = 2\n",
        "DATASET_SIZE = X_train.shape[0]\n",
        "BATCH_SIZE = 64\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "print('Selected device is {}'.format(device))\n",
        "# model = HybridModel(num_emotions=6).to(device)\n",
        "# print('Number of trainable params: ',sum(p.numel() for p in model.parameters()))\n",
        "# OPTIMIZER = torch.optim.SGD(model.parameters(),lr=0.01, weight_decay=1e-3, momentum=0.8)\n",
        "\n",
        "\n",
        "accuracies = []\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "losses = []\n",
        "\n",
        "# Initialize figure for live plot\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "\n",
        "# Assuming X_train, y_train, X_val, y_val are your training and validation data\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "learning_rates = [0.001, 0.01, 0.05, 0.1]\n",
        "momentums = [0.8, 0.85, 0.9, 0.95]\n",
        "dropout_rates = [0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "lstm_hidden_sizes = [64, 128, 256]  # Try different hidden sizes\n",
        "lstm_layers = [1, 2]\n",
        "# Add other hyperparameters you want to tune\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_hyperparameters = {}\n",
        "cuurent_hparam = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for momentum in momentums:\n",
        "        for dr in dropout_rates:\n",
        "            for hs in lstm_hidden_sizes:\n",
        "                for ly in lstm_layers:\n",
        "                    cuurent_hparam = {'lr': lr, 'momentum': momentum,\n",
        "                                      'dropout': dr, 'hidden_LSTM': hs, 'lstm_layers': ly}\n",
        "                    print(cuurent_hparam)\n",
        "                    model = HybridModel(\n",
        "                        num_emotions=6, dropout_rate=dr, hidden_size=hs, lstm_layers=ly).to(device)\n",
        "                    optimizer = torch.optim.SGD(\n",
        "                        model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "                    train_step = make_train_step(\n",
        "                        model, loss_fnc, optimizer=optimizer)\n",
        "                    validate = make_validate_fnc(model, loss_fnc)\n",
        "\n",
        "                    for epoch in range(EPOCHS):\n",
        "                        # Existing code...\n",
        "\n",
        "                        epoch_acc = 0\n",
        "                        epoch_loss = 0\n",
        "\n",
        "                        # shuffle data\n",
        "                        ind = np.random.permutation(DATASET_SIZE)\n",
        "                        X_train = X_train[ind, :, :, :, :]\n",
        "                        y_train = y_train[ind]\n",
        "\n",
        "                        iters = int(DATASET_SIZE / BATCH_SIZE)\n",
        "                        for i in range(iters):\n",
        "                            batch_start = i * BATCH_SIZE\n",
        "                            batch_end = min(\n",
        "                                batch_start + BATCH_SIZE, DATASET_SIZE)\n",
        "                            actual_batch_size = batch_end - batch_start\n",
        "                            X = X_train[batch_start:batch_end, :, :, :, :]\n",
        "                            Y = y_train[batch_start:batch_end]\n",
        "                            X_tensor = torch.tensor(X, device=device).float()\n",
        "                            Y_tensor = torch.tensor(\n",
        "                                Y, dtype=torch.long, device=device)\n",
        "\n",
        "                            loss, acc = train_step(X_tensor, Y_tensor)\n",
        "                            epoch_acc += acc * actual_batch_size / DATASET_SIZE\n",
        "                            epoch_loss += loss * actual_batch_size / DATASET_SIZE\n",
        "                            print(f\"\\r Epoch {epoch}: iteration {i}/{iters}\", end='')\n",
        "\n",
        "                        X_val_tensor = torch.tensor(\n",
        "                            X_val, device=device).float()\n",
        "                        Y_val_tensor = torch.tensor(\n",
        "                            y_val, dtype=torch.long, device=device)\n",
        "                        val_loss, val_acc, _ = validate(\n",
        "                            X_val_tensor, Y_val_tensor)\n",
        "                        val_losses.append(val_loss)\n",
        "                        val_accuracies.append(val_acc)\n",
        "\n",
        "                        if val_acc > best_accuracy:\n",
        "                            best_accuracy = val_acc\n",
        "                            best_hyperparameters = {\n",
        "                                'lr': lr, 'momentum': momentum, 'dropout': dr}\n",
        "                            print(best_hyperparameters)\n",
        "                            # Optionally, save the best model\n",
        "                            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "                        # Print progress\n",
        "                        # print('')\n",
        "                        print(f\"Epoch {epoch} --> loss:{epoch_loss:.4f}, acc:{epoch_acc:.2f}%, val_loss:{val_loss:.4f}, val_acc:{val_acc:.2f}%\")\n",
        "\n",
        "                        # Append metrics to lists\n",
        "                        losses.append(epoch_loss)\n",
        "                        accuracies.append(epoch_acc)\n",
        "\n",
        "                        # Print epoch metrics\n",
        "                        # clear_output(wait=True)\n",
        "                        # display(\n",
        "                        #     f\"Epoch {epoch} --> loss:{epoch_loss:.4f}, acc:{epoch_acc:.2f}%, val_loss:{val_loss:.4f}, val_acc:{val_acc:.2f}%\")\n",
        "\n",
        "                    # Reset model and optimizer for each hyperparameter combination\n"
      ],
      "metadata": {
        "id": "yZoSiiceB-ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "EPOCHS=100\n",
        "DATASET_SIZE = X_train.shape[0]\n",
        "BATCH_SIZE = 128\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "print('Selected device is {}'.format(device))\n",
        "\n",
        "\n",
        "# Set constants for early stopping\n",
        "PATIENCE = 10  # Number of epochs to wait before stopping if no improvement\n",
        "best_val_loss = float('inf')\n",
        "no_improvement_count = 0\n",
        "\n",
        "\n",
        "model = HybridModel(num_emotions=6, dropout_rate=0.2, hidden_size= 256,lstm_layers=1 ).to(device)\n",
        "OPTIMIZER = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "train_step = make_train_step(model, loss_fnc, optimizer=OPTIMIZER)\n",
        "validate = make_validate_fnc(model,loss_fnc)\n",
        "\n",
        "accuracies = []\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    # Existing code...\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # shuffle data\n",
        "    ind = np.random.permutation(DATASET_SIZE)\n",
        "    X_train = X_train[ind, :, :, :, :]\n",
        "    y_train = y_train[ind]\n",
        "\n",
        "    iters = int(DATASET_SIZE / BATCH_SIZE)\n",
        "    for i in range(iters):\n",
        "        batch_start = i * BATCH_SIZE\n",
        "        batch_end = min(batch_start + BATCH_SIZE, DATASET_SIZE)\n",
        "        actual_batch_size = batch_end - batch_start\n",
        "        X = X_train[batch_start:batch_end, :, :, :, :]\n",
        "        Y = y_train[batch_start:batch_end]\n",
        "        X_tensor = torch.tensor(X, device=device).float()\n",
        "        Y_tensor = torch.tensor(Y, dtype=torch.long, device=device)\n",
        "\n",
        "        loss, acc = train_step(X_tensor, Y_tensor)\n",
        "        epoch_acc += acc * actual_batch_size / DATASET_SIZE\n",
        "        epoch_loss += loss * actual_batch_size / DATASET_SIZE\n",
        "        print(f\"\\r Epoch {epoch}: iteration {i}/{iters}\", end='')\n",
        "\n",
        "    X_val_tensor = torch.tensor(X_val, device=device).float()\n",
        "    Y_val_tensor = torch.tensor(y_val, dtype=torch.long, device=device)\n",
        "    val_loss, val_acc, _ = validate(X_val_tensor, Y_val_tensor)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    losses.append(epoch_loss)\n",
        "    accuracies.append(epoch_acc)\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "\n",
        "    if no_improvement_count >= PATIENCE:\n",
        "        print(f\"Early stopping at epoch {epoch} as there's no improvement in validation loss.\")\n",
        "        break\n",
        "\n",
        "    # Print epoch metrics\n",
        "    display(f\"Epoch {epoch} --> loss:{epoch_loss:.4f}, acc:{epoch_acc:.2f}%, val_loss:{val_loss:.4f}, val_acc:{val_acc:.2f}%\")\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    # Update live plot\n",
        "    clear_output(wait=True)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accuracies, label='Training Accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.annotate(f'Last Epoch Acc: {epoch_acc:.2f}%', xy=(epoch-1, accuracies[-1]), xytext=(epoch-1, accuracies[-1] + 5),\n",
        "             arrowprops=dict(facecolor='black', arrowstyle='->'), fontsize=8)\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XxUKoA3oDCvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = os.path.join(os.getcwd(),'models')\n",
        "os.makedirs('models',exist_ok=True)\n",
        "torch.save(model.state_dict(),os.path.join(SAVE_PATH,'cnn_attention_lstm_model_8_e.pt'))\n",
        "print('Model is saved to {}'.format(os.path.join(SAVE_PATH,'cnn_attention_lstm_model_8_e.pt')))"
      ],
      "metadata": {
        "id": "PZzPaGGSDJlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_PATH = os.path.join(os.getcwd(),'models')\n",
        "model = HybridModel(len(EMOTIONS),dropout_rate=0.2, hidden_size= 256,lstm_layers=2 ).to(device)\n",
        "model.load_state_dict(torch.load(os.path.join(LOAD_PATH,'cnn_attention_lstm_model_8_d.pt')))\n",
        "print('Model is loaded from {}'.format(os.path.join(LOAD_PATH,'cnn_attention_lstm_model_8_d.pt')))"
      ],
      "metadata": {
        "id": "TDoIOs3UDKbr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}